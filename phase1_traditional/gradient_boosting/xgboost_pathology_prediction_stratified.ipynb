{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8982c8eb",
   "metadata": {},
   "source": [
    "# XGBoost pathology prediction (stratified preprocessed data)\n",
    "\n",
    "This notebook trains an XGBoost classifier to predict the `pathology` column using stratified, preprocessed datasets located in:\n",
    "\n",
    "`DDxPlus Dataset/preprocessed_stratified/`\n",
    "\n",
    "It includes: EDA, preprocessing pipelines, Stratified K-Fold training with early stopping, hyperparameter search, evaluation, SHAP explanations, and model saving.\n",
    "\n",
    "How to run:\n",
    "- Make a Python venv and install requirements in the first cell (uncomment and run).\n",
    "- Ensure the CSVs are present at `DDxPlus Dataset/preprocessed_stratified/train_preprocessed.csv`, `validation_preprocessed.csv`, `test_preprocessed.csv`.\n",
    "\n",
    "Outputs:\n",
    "- `models/xgb_pathology_stratified.joblib`\n",
    "- `outputs/validation_predictions.csv`\n",
    "\n",
    "---\n",
    "\n",
    "Notebook generated programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8321425",
   "metadata": {},
   "source": [
    "## Install required packages\n",
    "\n",
    "If you don't already have the required packages installed in your Python environment, run the cell below. In many environments the `%pip` magic is preferred inside notebooks (it ensures the kernel environment is used).\n",
    "\n",
    "Run this cell only once and skip if packages are already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baed80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this if you need to install packages in the notebook kernel\n",
    "# %pip install -q pandas numpy scikit-learn xgboost shap matplotlib seaborn joblib\n",
    "\n",
    "# If you prefer to install from the terminal, run the same pip command there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b0a0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix, roc_auc_score,\n",
    "                             log_loss, precision_recall_curve)\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# optional\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    shap = None\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff2f4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files:\n",
      "True /Users/denizcii/Desktop/sdp-chronicles/DDxPlus Dataset/preprocessed_stratified/train_preprocessed.csv\n",
      "True /Users/denizcii/Desktop/sdp-chronicles/DDxPlus Dataset/preprocessed_stratified/validation_preprocessed.csv\n",
      "True /Users/denizcii/Desktop/sdp-chronicles/DDxPlus Dataset/preprocessed_stratified/test_preprocessed.csv\n",
      "train shape: (936888, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIFFERENTIAL_DIAGNOSIS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATHOLOGY</th>\n",
       "      <th>EVIDENCES</th>\n",
       "      <th>INITIAL_EVIDENCE</th>\n",
       "      <th>SEX_ENCODED</th>\n",
       "      <th>NUM_EVIDENCES</th>\n",
       "      <th>NUM_DIFFERENTIAL_DX</th>\n",
       "      <th>TOP_PROBABILITY</th>\n",
       "      <th>CONFIDENCE_GAP</th>\n",
       "      <th>PATHOLOGY_ENCODED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>[['TSVP', 0.2249801997605792], ['Fibrillation ...</td>\n",
       "      <td>M</td>\n",
       "      <td>TSVP</td>\n",
       "      <td>['anxiete_s', 'cafe', 'douleurxx', 'douleurxx_...</td>\n",
       "      <td>douleurxx</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0.224980</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>[['Anémie', 0.1800172485572441], ['Ebola', 0.1...</td>\n",
       "      <td>F</td>\n",
       "      <td>Anémie</td>\n",
       "      <td>['Mauv_aliment', 'atcd_anem', 'atcd_fam_anem',...</td>\n",
       "      <td>rectorragie</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.052969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>[['RGO', 0.20809497395808063], ['Bronchite', 0...</td>\n",
       "      <td>M</td>\n",
       "      <td>RGO</td>\n",
       "      <td>['douleurxx', 'douleurxx_carac_@_sensible', 'd...</td>\n",
       "      <td>pyrosis</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.208095</td>\n",
       "      <td>0.043470</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE                             DIFFERENTIAL_DIAGNOSIS SEX PATHOLOGY  \\\n",
       "0   34  [['TSVP', 0.2249801997605792], ['Fibrillation ...   M      TSVP   \n",
       "1   73  [['Anémie', 0.1800172485572441], ['Ebola', 0.1...   F    Anémie   \n",
       "2   52  [['RGO', 0.20809497395808063], ['Bronchite', 0...   M       RGO   \n",
       "\n",
       "                                           EVIDENCES INITIAL_EVIDENCE  \\\n",
       "0  ['anxiete_s', 'cafe', 'douleurxx', 'douleurxx_...        douleurxx   \n",
       "1  ['Mauv_aliment', 'atcd_anem', 'atcd_fam_anem',...      rectorragie   \n",
       "2  ['douleurxx', 'douleurxx_carac_@_sensible', 'd...          pyrosis   \n",
       "\n",
       "   SEX_ENCODED  NUM_EVIDENCES  NUM_DIFFERENTIAL_DX  TOP_PROBABILITY  \\\n",
       "0            0             17                    6         0.224980   \n",
       "1            1             21                    9         0.180017   \n",
       "2            0             23                    9         0.208095   \n",
       "\n",
       "   CONFIDENCE_GAP  PATHOLOGY_ENCODED  \n",
       "0        0.005229                 44  \n",
       "1        0.052969                  3  \n",
       "2        0.043470                 35  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val shape: (129258, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIFFERENTIAL_DIAGNOSIS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATHOLOGY</th>\n",
       "      <th>EVIDENCES</th>\n",
       "      <th>INITIAL_EVIDENCE</th>\n",
       "      <th>SEX_ENCODED</th>\n",
       "      <th>NUM_EVIDENCES</th>\n",
       "      <th>NUM_DIFFERENTIAL_DX</th>\n",
       "      <th>TOP_PROBABILITY</th>\n",
       "      <th>CONFIDENCE_GAP</th>\n",
       "      <th>PATHOLOGY_ENCODED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>[['Bronchite', 0.33250589804545644], ['Rhinosi...</td>\n",
       "      <td>M</td>\n",
       "      <td>Rhinosinusite aigue</td>\n",
       "      <td>['douleurxx', 'douleurxx_carac_@_une_brûlure_o...</td>\n",
       "      <td>hyponos</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.332506</td>\n",
       "      <td>0.138893</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>[['Attaque de panique', 0.16960860783151496], ...</td>\n",
       "      <td>M</td>\n",
       "      <td>Attaque de panique</td>\n",
       "      <td>['atcdpsyfam', 'diaph', 'douleurxx', 'douleurx...</td>\n",
       "      <td>paresthesies_bilat</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0.169609</td>\n",
       "      <td>0.038329</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>[['IVRS ou virémie', 0.1947788896958362], ['Po...</td>\n",
       "      <td>F</td>\n",
       "      <td>IVRS ou virémie</td>\n",
       "      <td>['contact', 'dayc', 'diaph', 'douleurxx', 'dou...</td>\n",
       "      <td>rhino_clair</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0.194779</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE                             DIFFERENTIAL_DIAGNOSIS SEX  \\\n",
       "0   52  [['Bronchite', 0.33250589804545644], ['Rhinosi...   M   \n",
       "1   67  [['Attaque de panique', 0.16960860783151496], ...   M   \n",
       "2   62  [['IVRS ou virémie', 0.1947788896958362], ['Po...   F   \n",
       "\n",
       "             PATHOLOGY                                          EVIDENCES  \\\n",
       "0  Rhinosinusite aigue  ['douleurxx', 'douleurxx_carac_@_une_brûlure_o...   \n",
       "1   Attaque de panique  ['atcdpsyfam', 'diaph', 'douleurxx', 'douleurx...   \n",
       "2      IVRS ou virémie  ['contact', 'dayc', 'diaph', 'douleurxx', 'dou...   \n",
       "\n",
       "     INITIAL_EVIDENCE  SEX_ENCODED  NUM_EVIDENCES  NUM_DIFFERENTIAL_DX  \\\n",
       "0             hyponos            0             24                    6   \n",
       "1  paresthesies_bilat            0             26                   12   \n",
       "2         rhino_clair            1             21                    9   \n",
       "\n",
       "   TOP_PROBABILITY  CONFIDENCE_GAP  PATHOLOGY_ENCODED  \n",
       "0         0.332506        0.138893                 37  \n",
       "1         0.169609        0.038329                  5  \n",
       "2         0.194779        0.013022                 18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (142184, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIFFERENTIAL_DIAGNOSIS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATHOLOGY</th>\n",
       "      <th>EVIDENCES</th>\n",
       "      <th>INITIAL_EVIDENCE</th>\n",
       "      <th>SEX_ENCODED</th>\n",
       "      <th>NUM_EVIDENCES</th>\n",
       "      <th>NUM_DIFFERENTIAL_DX</th>\n",
       "      <th>TOP_PROBABILITY</th>\n",
       "      <th>CONFIDENCE_GAP</th>\n",
       "      <th>PATHOLOGY_ENCODED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>[['Tuberculose', 0.34186741055243264], ['Bronc...</td>\n",
       "      <td>F</td>\n",
       "      <td>Tuberculose</td>\n",
       "      <td>['HIV', 'cortico', 'crach_sg', 'drogues_IV', '...</td>\n",
       "      <td>crach_sg</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.341867</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>[['Pneumothorax spontané', 0.12926816396128354...</td>\n",
       "      <td>F</td>\n",
       "      <td>Péricardite</td>\n",
       "      <td>['B34.9', 'douleurxx', 'douleurxx_carac_@_un_c...</td>\n",
       "      <td>dyspn</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0.129268</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[['Fibrillation auriculaire/Flutter auriculair...</td>\n",
       "      <td>F</td>\n",
       "      <td>Fibrillation auriculaire/Flutter auriculaire</td>\n",
       "      <td>['ap_valve', 'dyspn', 'e10_e11', 'e66', 'etour...</td>\n",
       "      <td>ww_effort</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.017558</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE                             DIFFERENTIAL_DIAGNOSIS SEX  \\\n",
       "0    7  [['Tuberculose', 0.34186741055243264], ['Bronc...   F   \n",
       "1   28  [['Pneumothorax spontané', 0.12926816396128354...   F   \n",
       "2    6  [['Fibrillation auriculaire/Flutter auriculair...   F   \n",
       "\n",
       "                                      PATHOLOGY  \\\n",
       "0                                   Tuberculose   \n",
       "1                                   Péricardite   \n",
       "2  Fibrillation auriculaire/Flutter auriculaire   \n",
       "\n",
       "                                           EVIDENCES INITIAL_EVIDENCE  \\\n",
       "0  ['HIV', 'cortico', 'crach_sg', 'drogues_IV', '...         crach_sg   \n",
       "1  ['B34.9', 'douleurxx', 'douleurxx_carac_@_un_c...            dyspn   \n",
       "2  ['ap_valve', 'dyspn', 'e10_e11', 'e66', 'etour...        ww_effort   \n",
       "\n",
       "   SEX_ENCODED  NUM_EVIDENCES  NUM_DIFFERENTIAL_DX  TOP_PROBABILITY  \\\n",
       "0            1              9                    3         0.341867   \n",
       "1            1             13                   15         0.129268   \n",
       "2            1             11                   14         0.138400   \n",
       "\n",
       "   CONFIDENCE_GAP  PATHOLOGY_ENCODED  \n",
       "0        0.001673                 45  \n",
       "1        0.001353                 34  \n",
       "2        0.017558                 15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paths to stratified preprocessed data\n",
    "BASE = Path('/Users/denizcii/Desktop/sdp-chronicles')\n",
    "DATA_DIR = BASE / 'DDxPlus Dataset' / 'preprocessed_stratified'\n",
    "\n",
    "train_path = DATA_DIR / 'train_preprocessed.csv'\n",
    "val_path = DATA_DIR / 'validation_preprocessed.csv'\n",
    "test_path = DATA_DIR / 'test_preprocessed.csv'\n",
    "\n",
    "print('Looking for files:')\n",
    "print(train_path.exists(), train_path)\n",
    "print(val_path.exists(), val_path)\n",
    "print(test_path.exists(), test_path)\n",
    "\n",
    "# Load dataframes if present\n",
    "train_df = pd.read_csv(train_path) if train_path.exists() else None\n",
    "val_df = pd.read_csv(val_path) if val_path.exists() else None\n",
    "test_df = pd.read_csv(test_path) if test_path.exists() else None\n",
    "\n",
    "# Show quick heads\n",
    "for name, df in [('train', train_df), ('val', val_df), ('test', test_df)]:\n",
    "    if df is None:\n",
    "        print(f'{name} dataframe not found')\n",
    "    else:\n",
    "        print(f\"{name} shape:\", df.shape)\n",
    "        display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca715b2",
   "metadata": {},
   "source": [
    "## Quick Data Exploration\n",
    "\n",
    "Let's check:\n",
    "1. Missing values\n",
    "2. Target (pathology) distribution\n",
    "3. Feature types and basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values in training set:\")\n",
    "display(train_df.isnull().sum()[train_df.isnull().sum() > 0])\n",
    "\n",
    "# Check target distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "train_df['pathology'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Distribution of Pathology Classes (Training Set)')\n",
    "plt.xlabel('Pathology Class')\n",
    "plt.ylabel('Proportion')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Basic feature info\n",
    "print(\"\\nFeature types:\")\n",
    "display(train_df.dtypes)\n",
    "\n",
    "# Basic statistics for numeric columns\n",
    "print(\"\\nNumeric feature statistics:\")\n",
    "display(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd299f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb6504a",
   "metadata": {},
   "source": [
    "## Prepare Features and Labels\n",
    "\n",
    "We'll:\n",
    "1. Separate features and target\n",
    "2. Create preprocessing pipeline for categorical and numeric features\n",
    "3. Set up cross-validation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc95e01",
   "metadata": {},
   "source": [
    "## Train XGBoost Model\n",
    "\n",
    "1. Separate features and target (pathology)\n",
    "2. Train XGBoost classifier\n",
    "3. Make predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a67391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_df.drop(['pathology'], axis=1)\n",
    "y_train = train_df['pathology']\n",
    "\n",
    "X_val = val_df.drop(['pathology'], axis=1)\n",
    "y_val = val_df['pathology']\n",
    "\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Validation features shape:\", X_val.shape)\n",
    "\n",
    "# Initialize and train XGBoost classifier\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'  # for multiclass classification\n",
    ")\n",
    "\n",
    "# Train with early stopping using validation set\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nBest iteration:\", xgb_clf.best_iteration)\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(BASE / 'models', exist_ok=True)\n",
    "os.makedirs(BASE / 'outputs', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = BASE / 'models' / 'xgb_pathology_stratified.joblib'\n",
    "joblib.dump(xgb_clf, model_path)\n",
    "print(f\"\\nModel saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac20b8",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate model performance on validation set:\n",
    "1. Make predictions\n",
    "2. Calculate accuracy, precision, recall, F1 score\n",
    "3. Save predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76673c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (936888, 6)\n",
      "Validation features shape: (129258, 6)\n",
      "Test features shape: (142184, 6)\n",
      "\n",
      "Features used: ['AGE', 'SEX_ENCODED', 'NUM_EVIDENCES', 'NUM_DIFFERENTIAL_DX', 'TOP_PROBABILITY', 'CONFIDENCE_GAP']\n",
      "[0]\tvalidation_0-mlogloss:3.03081\n",
      "[1]\tvalidation_0-mlogloss:2.76426\n",
      "[2]\tvalidation_0-mlogloss:2.56765\n",
      "[3]\tvalidation_0-mlogloss:2.42171\n",
      "[4]\tvalidation_0-mlogloss:2.30142\n",
      "[5]\tvalidation_0-mlogloss:2.19968\n",
      "[6]\tvalidation_0-mlogloss:2.10952\n",
      "[7]\tvalidation_0-mlogloss:2.03075\n",
      "[8]\tvalidation_0-mlogloss:1.96291\n",
      "[9]\tvalidation_0-mlogloss:1.90054\n",
      "[10]\tvalidation_0-mlogloss:1.84561\n",
      "[11]\tvalidation_0-mlogloss:1.79637\n",
      "[12]\tvalidation_0-mlogloss:1.75042\n",
      "[13]\tvalidation_0-mlogloss:1.70891\n",
      "[14]\tvalidation_0-mlogloss:1.67017\n",
      "[15]\tvalidation_0-mlogloss:1.63309\n",
      "[16]\tvalidation_0-mlogloss:1.59937\n",
      "[17]\tvalidation_0-mlogloss:1.56909\n",
      "[18]\tvalidation_0-mlogloss:1.53965\n",
      "[19]\tvalidation_0-mlogloss:1.51337\n",
      "[20]\tvalidation_0-mlogloss:1.48825\n",
      "[21]\tvalidation_0-mlogloss:1.46500\n",
      "[22]\tvalidation_0-mlogloss:1.44311\n",
      "[23]\tvalidation_0-mlogloss:1.42275\n",
      "[24]\tvalidation_0-mlogloss:1.40402\n",
      "[25]\tvalidation_0-mlogloss:1.38601\n",
      "[26]\tvalidation_0-mlogloss:1.36876\n",
      "[27]\tvalidation_0-mlogloss:1.35216\n",
      "[28]\tvalidation_0-mlogloss:1.33736\n",
      "[29]\tvalidation_0-mlogloss:1.32285\n",
      "[30]\tvalidation_0-mlogloss:1.30917\n",
      "[31]\tvalidation_0-mlogloss:1.29616\n",
      "[32]\tvalidation_0-mlogloss:1.28310\n",
      "[33]\tvalidation_0-mlogloss:1.27158\n",
      "[34]\tvalidation_0-mlogloss:1.26092\n",
      "[35]\tvalidation_0-mlogloss:1.25033\n",
      "[36]\tvalidation_0-mlogloss:1.23939\n",
      "[37]\tvalidation_0-mlogloss:1.22913\n",
      "[38]\tvalidation_0-mlogloss:1.21919\n",
      "[39]\tvalidation_0-mlogloss:1.21002\n",
      "[40]\tvalidation_0-mlogloss:1.20172\n",
      "[41]\tvalidation_0-mlogloss:1.19257\n",
      "[42]\tvalidation_0-mlogloss:1.18470\n",
      "[43]\tvalidation_0-mlogloss:1.17644\n",
      "[44]\tvalidation_0-mlogloss:1.16855\n",
      "[45]\tvalidation_0-mlogloss:1.16104\n",
      "[46]\tvalidation_0-mlogloss:1.15291\n",
      "[47]\tvalidation_0-mlogloss:1.14575\n",
      "[48]\tvalidation_0-mlogloss:1.13844\n",
      "[49]\tvalidation_0-mlogloss:1.13146\n",
      "[50]\tvalidation_0-mlogloss:1.12468\n",
      "[51]\tvalidation_0-mlogloss:1.11799\n",
      "[52]\tvalidation_0-mlogloss:1.11197\n",
      "[53]\tvalidation_0-mlogloss:1.10609\n",
      "[54]\tvalidation_0-mlogloss:1.09976\n",
      "[55]\tvalidation_0-mlogloss:1.09383\n",
      "[56]\tvalidation_0-mlogloss:1.08774\n",
      "[57]\tvalidation_0-mlogloss:1.08265\n",
      "[58]\tvalidation_0-mlogloss:1.07694\n",
      "[59]\tvalidation_0-mlogloss:1.07253\n",
      "[60]\tvalidation_0-mlogloss:1.06686\n",
      "[61]\tvalidation_0-mlogloss:1.06106\n",
      "[62]\tvalidation_0-mlogloss:1.05604\n",
      "[63]\tvalidation_0-mlogloss:1.05083\n",
      "[64]\tvalidation_0-mlogloss:1.04535\n",
      "[65]\tvalidation_0-mlogloss:1.04092\n",
      "[66]\tvalidation_0-mlogloss:1.03671\n",
      "[67]\tvalidation_0-mlogloss:1.03159\n",
      "[68]\tvalidation_0-mlogloss:1.02761\n",
      "[69]\tvalidation_0-mlogloss:1.02292\n",
      "[70]\tvalidation_0-mlogloss:1.01891\n",
      "[71]\tvalidation_0-mlogloss:1.01509\n",
      "[72]\tvalidation_0-mlogloss:1.01121\n",
      "[73]\tvalidation_0-mlogloss:1.00672\n",
      "[74]\tvalidation_0-mlogloss:1.00289\n",
      "[75]\tvalidation_0-mlogloss:0.99913\n",
      "[76]\tvalidation_0-mlogloss:0.99412\n",
      "[77]\tvalidation_0-mlogloss:0.99132\n",
      "[78]\tvalidation_0-mlogloss:0.98672\n",
      "[79]\tvalidation_0-mlogloss:0.98333\n",
      "[80]\tvalidation_0-mlogloss:0.97963\n",
      "[81]\tvalidation_0-mlogloss:0.97549\n",
      "[82]\tvalidation_0-mlogloss:0.97224\n",
      "[83]\tvalidation_0-mlogloss:0.96825\n",
      "[84]\tvalidation_0-mlogloss:0.96461\n",
      "[85]\tvalidation_0-mlogloss:0.96059\n",
      "[86]\tvalidation_0-mlogloss:0.95756\n",
      "[87]\tvalidation_0-mlogloss:0.95400\n",
      "[88]\tvalidation_0-mlogloss:0.94970\n",
      "[89]\tvalidation_0-mlogloss:0.94622\n",
      "[90]\tvalidation_0-mlogloss:0.94233\n",
      "[91]\tvalidation_0-mlogloss:0.93907\n",
      "[92]\tvalidation_0-mlogloss:0.93604\n",
      "[93]\tvalidation_0-mlogloss:0.93268\n",
      "[94]\tvalidation_0-mlogloss:0.92930\n",
      "[95]\tvalidation_0-mlogloss:0.92587\n",
      "[96]\tvalidation_0-mlogloss:0.92274\n",
      "[97]\tvalidation_0-mlogloss:0.91931\n",
      "[98]\tvalidation_0-mlogloss:0.91622\n",
      "[99]\tvalidation_0-mlogloss:0.91338\n",
      "\n",
      "Model saved to /Users/denizcii/Desktop/sdp-chronicles/models/xgb_pathology_stratified.joblib\n",
      "Predictions saved to /Users/denizcii/Desktop/sdp-chronicles/outputs/test_predictions.csv\n",
      "\n",
      "Model Performance on Test Set:\n",
      "Accuracy: 0.7266218421200697\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      3880\n",
      "           1       0.57      0.38      0.46      2956\n",
      "           2       0.66      0.76      0.70      2389\n",
      "           3       0.69      0.56      0.62      7085\n",
      "           4       0.94      0.99      0.96      2674\n",
      "           5       0.60      0.58      0.59      3481\n",
      "           6       0.90      0.91      0.90      2592\n",
      "           7       0.65      1.00      0.79        36\n",
      "           8       0.79      0.62      0.69      3689\n",
      "           9       0.28      0.15      0.20      1260\n",
      "          10       0.96      0.99      0.97       788\n",
      "          11       0.69      0.94      0.80      2912\n",
      "          12       0.62      0.10      0.17       100\n",
      "          13       0.63      0.72      0.67      3836\n",
      "          14       0.95      0.91      0.93      2408\n",
      "          15       0.89      0.83      0.86      2912\n",
      "          16       0.82      0.87      0.84       800\n",
      "          17       0.55      0.76      0.64      2818\n",
      "          18       0.77      0.72      0.74      8994\n",
      "          19       0.68      0.90      0.77      3383\n",
      "          20       0.86      0.82      0.84       381\n",
      "          21       0.66      0.82      0.73      1370\n",
      "          22       0.65      0.27      0.38      1651\n",
      "          23       0.82      0.73      0.77      2523\n",
      "          24       0.56      0.34      0.42      1551\n",
      "          25       0.44      0.31      0.36      2641\n",
      "          26       0.65      0.62      0.63      2653\n",
      "          27       0.98      0.99      0.99      3878\n",
      "          28       0.84      0.97      0.90      3620\n",
      "          29       0.79      0.80      0.80      8604\n",
      "          30       0.93      0.87      0.90      3607\n",
      "          31       0.57      0.38      0.46      1420\n",
      "          32       0.69      0.65      0.67      2983\n",
      "          33       0.70      0.82      0.76      3735\n",
      "          34       0.62      0.72      0.66      3180\n",
      "          35       0.45      0.45      0.45      3624\n",
      "          36       0.65      0.93      0.76      3382\n",
      "          37       0.60      0.29      0.39      1900\n",
      "          38       0.64      0.83      0.72      2865\n",
      "          39       0.84      0.68      0.75      3582\n",
      "          40       0.56      0.80      0.66      2994\n",
      "          41       0.45      0.61      0.51      2560\n",
      "          42       0.80      0.68      0.73      2116\n",
      "          43       0.87      0.71      0.78      3083\n",
      "          44       0.59      0.61      0.60      2596\n",
      "          45       0.90      0.90      0.90      2237\n",
      "          46       0.91      0.96      0.93      4046\n",
      "          47       0.77      0.79      0.78      2009\n",
      "          48       0.78      0.65      0.70      2400\n",
      "\n",
      "    accuracy                           0.73    142184\n",
      "   macro avg       0.72      0.70      0.70    142184\n",
      "weighted avg       0.73      0.73      0.72    142184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training data - keep only numeric columns and encode categorical ones\n",
    "numeric_features = ['AGE', 'SEX_ENCODED', 'NUM_EVIDENCES', 'NUM_DIFFERENTIAL_DX', 'TOP_PROBABILITY', 'CONFIDENCE_GAP']\n",
    "\n",
    "# Select only numeric features for training\n",
    "X_train = train_df[numeric_features]\n",
    "y_train = train_df['PATHOLOGY_ENCODED']  # use encoded pathology as target\n",
    "\n",
    "# Prepare test set\n",
    "X_test = test_df[numeric_features]\n",
    "y_test_true = test_df['PATHOLOGY'].copy()  # save original labels for evaluation\n",
    "y_test_encoded = test_df['PATHOLOGY_ENCODED'].copy()  # save encoded labels for model\n",
    "\n",
    "# Prepare validation set\n",
    "X_val = val_df[numeric_features]\n",
    "y_val = val_df['PATHOLOGY_ENCODED']\n",
    "\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Validation features shape:\", X_val.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"\\nFeatures used:\", numeric_features)\n",
    "\n",
    "# Initialize and train XGBoost classifier\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'  # for multiclass classification\n",
    ")\n",
    "\n",
    "# Train with validation monitoring\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred_encoded = xgb_clf.predict(X_test)\n",
    "y_pred_proba = xgb_clf.predict_proba(X_test)\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(BASE / 'models', exist_ok=True)\n",
    "os.makedirs(BASE / 'outputs', exist_ok=True)\n",
    "\n",
    "# Save model and predictions\n",
    "model_path = BASE / 'models' / 'xgb_pathology_stratified.joblib'\n",
    "preds_path = BASE / 'outputs' / 'test_predictions.csv'\n",
    "\n",
    "joblib.dump(xgb_clf, model_path)\n",
    "print(f\"\\nModel saved to {model_path}\")\n",
    "\n",
    "# Create a mapping dictionary from encoded to original labels\n",
    "pathology_mapping = dict(zip(train_df['PATHOLOGY_ENCODED'], train_df['PATHOLOGY']))\n",
    "y_pred = [pathology_mapping[pred] for pred in y_pred_encoded]\n",
    "\n",
    "# Save predictions with probabilities\n",
    "pred_df = pd.DataFrame({\n",
    "    'true_pathology': y_test_true,\n",
    "    'predicted_pathology': y_pred,\n",
    "    'predicted_pathology_encoded': y_pred_encoded\n",
    "})\n",
    "\n",
    "# Add probability columns for each class\n",
    "for i, col in enumerate(xgb_clf.classes_):\n",
    "    pred_df[f'prob_class_{col}'] = y_pred_proba[:, i]\n",
    "\n",
    "pred_df.to_csv(preds_path, index=False)\n",
    "print(f\"Predictions saved to {preds_path}\")\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nModel Performance on Test Set:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_encoded, y_pred_encoded))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4de09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data columns:\n",
      "['AGE', 'DIFFERENTIAL_DIAGNOSIS', 'SEX', 'PATHOLOGY', 'EVIDENCES', 'INITIAL_EVIDENCE', 'SEX_ENCODED', 'NUM_EVIDENCES', 'NUM_DIFFERENTIAL_DX', 'TOP_PROBABILITY', 'CONFIDENCE_GAP', 'PATHOLOGY_ENCODED']\n",
      "\n",
      "Test data columns:\n",
      "['AGE', 'DIFFERENTIAL_DIAGNOSIS', 'SEX', 'PATHOLOGY', 'EVIDENCES', 'INITIAL_EVIDENCE', 'SEX_ENCODED', 'NUM_EVIDENCES', 'NUM_DIFFERENTIAL_DX', 'TOP_PROBABILITY', 'CONFIDENCE_GAP', 'PATHOLOGY_ENCODED']\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(\"Training data columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "print(\"\\nTest data columns:\")\n",
    "print(test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da58bda",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "\n",
    "Let's analyze why we might be getting lower accuracy:\n",
    "1. Confusion Matrix to see which classes are confused\n",
    "2. Feature Importance to see if we're missing important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "sns.heatmap(cm, cmap='Blues', fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': numeric_features,\n",
    "    'importance': xgb_clf.feature_importances_\n",
    "})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print most confused pairs\n",
    "print(\"\\nMost Confused Class Pairs:\")\n",
    "for i in range(len(xgb_clf.classes_)):\n",
    "    for j in range(i+1, len(xgb_clf.classes_)):\n",
    "        if cm[i][j] + cm[j][i] > 0:  # if there are any confusions between these classes\n",
    "            true_label_i = pathology_mapping[i]\n",
    "            true_label_j = pathology_mapping[j]\n",
    "            confusion_sum = cm[i][j] + cm[j][i]\n",
    "            print(f\"{true_label_i} ↔ {true_label_j}: {confusion_sum} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2017f1",
   "metadata": {},
   "source": [
    "## Improved Model with Text Features\n",
    "\n",
    "Let's improve the model by:\n",
    "1. Including encoded text features (DIFFERENTIAL_DIAGNOSIS, EVIDENCES)\n",
    "2. Using a proper preprocessing pipeline\n",
    "3. Increasing model complexity slightly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
